# MultimediaAI
Advanced AI model that generates high-quality images from textual descriptions using Stable Diffusion. Our project aims to leverage state-of-the-art deep learning techniques to bridge the gap between text and visual content generation.

# Citations
•	keras: https://colab.research.google.com/github/keras-team/keras-io/blob/master/guides/ipynb/keras_cv/generate_images_with_stable_diffusion.ipynb?authuser=1#scrollTo=JBn1gj5QVMSc <br>
•	Text Generation: https://colab.research.google.com/github/bandiajay/Generative-AI/blob/main/03_Text_Generation.ipynb#scrollTo=kCuayJDZuDQd <br>
•	DALL·E: Creating images from text | OpenAI <br>
•	[2301.12503] AudioLDM: Text-to-Audio Generation with Latent Diffusion Models (arxiv.org) <br>
•	Hugging Face Transformers Library: https://huggingface.co/transformers/ <br>
•	Diffusers Library by Hugging Face: https://github.com/huggingface/diffusers <br>
•	Google Text-to-Speech (gTTS): https://gtts.readthedocs.io/ <br>
•	Python Imaging Library (PIL): https://pillow.readthedocs.io/ <br>
•	IPython Display: https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html <br>

